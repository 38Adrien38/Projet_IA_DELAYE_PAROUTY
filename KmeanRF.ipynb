{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e39990",
   "metadata": {},
   "source": [
    "# K-means avec Random Forest\n",
    "\n",
    "Ce notebook regroupe tout le code nécessaire pour entraîner une Random Forest à repérer les pixels du fond puis appliquer un K-means amélioré sur les structures d’images en discriminant les pixels du fond. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52fa251",
   "metadata": {},
   "source": [
    "### Imports et fonctions utilitaires\n",
    "La cellule qui suit rassemble toutes les bibliothèques nécessaires (NumPy, Pandas, scikit-learn, scikit-image…) normalement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ff73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Core improved K-means segmentation primitives.\n",
    "This cell is a verbatim port of `improved_kmeans_segmentation.py`\n",
    "so that the notebook can run standalone without external modules.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from skimage import exposure, morphology, util\n",
    "from skimage.feature import hessian_matrix, structure_tensor\n",
    "\n",
    "try:  # scikit-image <=0.22\n",
    "    from skimage.feature import hessian_matrix_eigvals\n",
    "except ImportError:  # scikit-image >=0.23\n",
    "    from skimage.feature import hessian_matrix_eigenvalues as hessian_matrix_eigvals\n",
    "\n",
    "try:\n",
    "    from skimage.feature import structure_tensor_eigvals\n",
    "except ImportError:\n",
    "    from skimage.feature import structure_tensor_eigenvalues as structure_tensor_eigvals\n",
    "\n",
    "from skimage.filters import gaussian, laplace, sobel\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "\n",
    "def _structure_tensor_eigenvalues(\n",
    "    Axx: np.ndarray, Axy: np.ndarray, Ayy: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Compat wrapper to support multiple scikit-image signatures.\"\"\"\n",
    "\n",
    "    try:\n",
    "        return structure_tensor_eigvals(Axx, Axy, Ayy)\n",
    "    except TypeError:\n",
    "        return structure_tensor_eigvals((Axx, Axy, Ayy))\n",
    "\n",
    "\n",
    "def _hessian_matrix_eigenvalues(\n",
    "    Hxx: np.ndarray, Hxy: np.ndarray, Hyy: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    try:\n",
    "        return hessian_matrix_eigvals(Hxx, Hxy, Hyy)\n",
    "    except TypeError:\n",
    "        return hessian_matrix_eigvals((Hxx, Hxy, Hyy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3461795",
   "metadata": {},
   "source": [
    "## Data Loading Utilities\n",
    "Cette section définit une fonction `load_png_stack` qui lit un dossier d’images PNG en niveaux de gris, les trie dans l’ordre numérique et les empile dans un tableau NumPy. On obtient d’un côté la liste des chemins (pratique pour tracer ou sauvegarder) et de l’autre un cube `nombre_de_slices × hauteur × largeur` qui servira de base au reste du pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2432bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_png_stack(\n",
    "    img_dir: str | Path, limit: int | None = None\n",
    ") -> Tuple[List[Path], np.ndarray]:\n",
    "    \"\"\"Load a stack of grayscale PNG slices sorted by numeric stem.\"\"\"\n",
    "\n",
    "    img_dir = Path(img_dir)\n",
    "    pngs = sorted(\n",
    "        img_dir.glob(\"*.png\"),\n",
    "        key=lambda f: int(\"\".join(ch for ch in f.stem if ch.isdigit()) or 0),\n",
    "    )\n",
    "    if not pngs:\n",
    "        raise FileNotFoundError(f\"No PNG image found in {img_dir}\")\n",
    "\n",
    "    if limit is not None:\n",
    "        pngs = pngs[:limit]\n",
    "\n",
    "    shapes = {Image.open(p).size for p in pngs}\n",
    "    if len(shapes) != 1:\n",
    "        raise ValueError(f\"Images with different shapes were detected: {shapes}\")\n",
    "\n",
    "    arrays: List[np.ndarray] = []\n",
    "    for path in pngs:\n",
    "        with Image.open(path) as img:\n",
    "            arrays.append(np.array(img.convert(\"L\"), dtype=np.uint8))\n",
    "\n",
    "    stack = np.stack(arrays, axis=0)\n",
    "    return pngs, stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ca5e5",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Ici on transforme chaque image en un jeu de caractéristiques riche : intensité, flous gaussiens multi-échelles, gradients, Laplacien, tenseur de structure, Hessien, variance locale et coordonnées normalisées. Tout est standardisé pour que les futures étapes de clustering reçoivent une matrice `pixels × features` prête à l’emploi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af984424",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureBundle:\n",
    "    matrix: np.ndarray\n",
    "    maps: Dict[str, np.ndarray]\n",
    "\n",
    "\n",
    "def _prepare_slice(raw_slice: np.ndarray, clip_limit: float = 0.015) -> np.ndarray:\n",
    "    \"\"\"Normalize slice to float32 within [0, 1] and enhance contrast.\"\"\"\n",
    "\n",
    "    img = raw_slice.astype(np.float32) / 255.0\n",
    "    img = exposure.equalize_adapthist(img, clip_limit=clip_limit)\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "\n",
    "def build_feature_bundle(\n",
    "    raw_slice: np.ndarray, *, sigmas: Sequence[float] = (0.8, 1.6, 2.4)\n",
    ") -> FeatureBundle:\n",
    "    \"\"\"Create a per-pixel feature stack for K-means segmentation.\"\"\"\n",
    "\n",
    "    img = _prepare_slice(raw_slice)\n",
    "    h, w = img.shape\n",
    "\n",
    "    features: List[np.ndarray] = []\n",
    "    maps: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    maps[\"intensity\"] = img\n",
    "    features.append(img)\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        smooth = gaussian(img, sigma=sigma, preserve_range=True)\n",
    "        maps[f\"gauss_{sigma:.1f}\"] = smooth\n",
    "        features.append(smooth)\n",
    "\n",
    "    grad_mag = sobel(img)\n",
    "    maps[\"gradient\"] = grad_mag\n",
    "    features.append(grad_mag)\n",
    "\n",
    "    lap = np.abs(laplace(img, ksize=3))\n",
    "    maps[\"laplacian\"] = lap\n",
    "    features.append(lap)\n",
    "\n",
    "    Axx, Axy, Ayy = structure_tensor(img, sigma=1.0, mode=\"reflect\")\n",
    "    l1, l2 = _structure_tensor_eigenvalues(Axx, Axy, Ayy)\n",
    "    maps[\"st_eig1\"], maps[\"st_eig2\"] = l1, l2\n",
    "    features.extend([l1, l2])\n",
    "\n",
    "    Hxx, Hxy, Hyy = hessian_matrix(img, sigma=1.8, order=\"rc\", mode=\"reflect\")\n",
    "    h1, h2 = _hessian_matrix_eigenvalues(Hxx, Hxy, Hyy)\n",
    "    maps[\"hess_eig1\"], maps[\"hess_eig2\"] = h1, h2\n",
    "    features.extend([h1, h2])\n",
    "\n",
    "    gauss1 = gaussian(img, sigma=1.2, preserve_range=True)\n",
    "    gauss2 = gaussian(img ** 2, sigma=1.2, preserve_range=True)\n",
    "    variance = np.clip(gauss2 - gauss1 ** 2, 0.0, None)\n",
    "    maps[\"variance\"] = variance\n",
    "    features.append(variance)\n",
    "\n",
    "    yy, xx = np.mgrid[0:h, 0:w].astype(np.float32)\n",
    "    xx_norm = xx / max(w - 1, 1)\n",
    "    yy_norm = yy / max(h - 1, 1)\n",
    "    radius = np.sqrt((xx_norm - 0.5) ** 2 + (yy_norm - 0.5) ** 2)\n",
    "    border = np.minimum.reduce([xx_norm, 1 - xx_norm, yy_norm, 1 - yy_norm])\n",
    "\n",
    "    maps[\"x_norm\"], maps[\"y_norm\"], maps[\"radius\"], maps[\"border\"] = (\n",
    "        xx_norm,\n",
    "        yy_norm,\n",
    "        radius,\n",
    "        border,\n",
    "    )\n",
    "    features.extend([xx_norm, yy_norm, radius, border])\n",
    "\n",
    "    stack = np.stack(features, axis=-1)\n",
    "    flat = stack.reshape(-1, stack.shape[-1]).astype(np.float32)\n",
    "    flat = (flat - flat.mean(axis=0)) / (flat.std(axis=0) + 1e-6)\n",
    "\n",
    "    return FeatureBundle(matrix=flat, maps=maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab1b7b",
   "metadata": {},
   "source": [
    "## Clustering & Post-processing\n",
    "Cette partie regroupe le cœur du K-means : on entraîne soit un K-means classique soit un MiniBatchKMeans (plus rapide) sur les caractéristiques des pixels (intensité etc), on identifie le cluster de fond via des heuristiques simples, puis on nettoie les étiquettes (suppression des petits objets, fermeture morphologique, remplissage des trous). Les fonctions `segment_slice` et `segment_stack` appliquent le tout à une image ou à une pile entière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678009ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_clusterer(\n",
    "    X: np.ndarray, n_clusters: int, subsample: int, random_state: int, method: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = check_random_state(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    if method == \"kmeans\":\n",
    "        estimator = KMeans(\n",
    "            n_clusters=n_clusters,\n",
    "            n_init=\"auto\",\n",
    "            random_state=random_state,\n",
    "            max_iter=400,\n",
    "        )\n",
    "        estimator.fit(X)\n",
    "    else:\n",
    "        choose = min(subsample, n_samples)\n",
    "        idx = rng.choice(n_samples, choose, replace=False)\n",
    "        estimator = MiniBatchKMeans(\n",
    "            n_clusters=n_clusters,\n",
    "            batch_size=4096,\n",
    "            n_init=\"auto\",\n",
    "            reassignment_ratio=0.01,\n",
    "            max_iter=200,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        estimator.fit(X[idx])\n",
    "\n",
    "    labels = estimator.predict(X)\n",
    "    return labels, getattr(estimator, \"cluster_centers_\", None)\n",
    "\n",
    "\n",
    "def _pick_background_label(\n",
    "    labels: np.ndarray, maps: Dict[str, np.ndarray], margin: int = 6\n",
    ") -> int:\n",
    "    h, w = maps[\"intensity\"].shape\n",
    "    label_img = labels.reshape(h, w)\n",
    "    unique_labels = np.unique(label_img)\n",
    "\n",
    "    border_mask = np.zeros_like(label_img, dtype=bool)\n",
    "    border_mask[:margin, :] = True\n",
    "    border_mask[-margin:, :] = True\n",
    "    border_mask[:, :margin] = True\n",
    "    border_mask[:, -margin:] = True\n",
    "\n",
    "    grad = maps[\"gradient\"]\n",
    "    intensity = maps[\"gauss_0.8\"] if \"gauss_0.8\" in maps else maps[\"intensity\"]\n",
    "\n",
    "    best_label = int(unique_labels[0])\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for lbl in unique_labels:\n",
    "        mask = label_img == lbl\n",
    "        area_ratio = mask.mean()\n",
    "        if area_ratio == 0:\n",
    "            continue\n",
    "\n",
    "        border_ratio = mask[border_mask].mean()\n",
    "        grad_mean = float(grad[mask].mean())\n",
    "        intensity_mean = float(intensity[mask].mean())\n",
    "\n",
    "        score = (\n",
    "            1.8 * border_ratio\n",
    "            + 0.7 * area_ratio\n",
    "            - 1.1 * grad_mean\n",
    "            - 0.3 * intensity_mean\n",
    "        )\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_label = int(lbl)\n",
    "\n",
    "    return best_label\n",
    "\n",
    "\n",
    "def _post_process(\n",
    "    label_img: np.ndarray, maps: Dict[str, np.ndarray], *, min_size: int = 80, hole_size: int = 96\n",
    ") -> np.ndarray:\n",
    "    h, w = label_img.shape\n",
    "    cleaned = np.zeros((h, w), dtype=np.uint8)\n",
    "    next_label = 1\n",
    "\n",
    "    for lbl in np.unique(label_img):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = label_img == lbl\n",
    "        mask = morphology.remove_small_objects(mask, min_size=min_size)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        mask = morphology.binary_closing(mask, morphology.disk(2))\n",
    "        mask = morphology.remove_small_holes(mask, area_threshold=hole_size)\n",
    "\n",
    "        if mask.any():\n",
    "            cleaned[mask] = next_label\n",
    "            next_label += 1\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def segment_slice(\n",
    "    raw_slice: np.ndarray,\n",
    "    *,\n",
    "    k_structures: int = 12,\n",
    "    extra_background_clusters: int = 2,\n",
    "    subsample: int = 120_000,\n",
    "    random_state: int = 42,\n",
    "    method: str = \"minibatch\",\n",
    ") -> Tuple[np.ndarray, FeatureBundle]:\n",
    "    bundle = build_feature_bundle(raw_slice)\n",
    "    k_total = k_structures + extra_background_clusters\n",
    "\n",
    "    labels, _ = _fit_clusterer(bundle.matrix, k_total, subsample, random_state, method)\n",
    "    h, w = raw_slice.shape\n",
    "\n",
    "    label_img = labels.reshape(h, w)\n",
    "    background_label = _pick_background_label(labels, bundle.maps)\n",
    "    label_img[label_img == background_label] = 0\n",
    "\n",
    "    label_img, _, _ = relabel_sequential(label_img)\n",
    "\n",
    "    processed = _post_process(label_img, bundle.maps)\n",
    "    return processed, bundle\n",
    "\n",
    "\n",
    "def segment_stack(\n",
    "    stack: np.ndarray,\n",
    "    *,\n",
    "    k_structures: int = 12,\n",
    "    method: str = \"minibatch\",\n",
    "    subsample: int = 120_000,\n",
    "    random_state: int = 42,\n",
    ") -> np.ndarray:\n",
    "    preds: List[np.ndarray] = []\n",
    "    start = time.time()\n",
    "\n",
    "    for idx, slc in enumerate(stack):\n",
    "        pred, _ = segment_slice(\n",
    "            slc,\n",
    "            k_structures=k_structures,\n",
    "            extra_background_clusters=2,\n",
    "            subsample=subsample,\n",
    "            random_state=random_state + idx,\n",
    "            method=method,\n",
    "        )\n",
    "        preds.append(pred)\n",
    "\n",
    "        if (idx + 1) % 25 == 0:\n",
    "            elapsed = time.time() - start\n",
    "            rate = (idx + 1) / max(elapsed, 1e-6)\n",
    "            print(f\"Processed {idx + 1} slices in {elapsed:.1f}s ({rate:.2f} slices/s)\")\n",
    "\n",
    "    return np.stack(preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b57b3",
   "metadata": {},
   "source": [
    "## Evaluation Helpers\n",
    "Les fonctions de cette section servent à sauvegarder les résultats et à mesurer leur qualité. `save_predictions` écrit un CSV/NPY prêt à être soumis au challenge, `load_ground_truth` reconstitue les masques à partir du CSV d’annotations et `evaluate_ari` calcule l’Adjusted Rand Index en ignorant le fond. `run_demo` combine le tout pour un test rapide sur un sous-ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc0f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(\n",
    "    preds: np.ndarray, out_csv: str | Path, save_npy: bool = True\n",
    ") -> None:\n",
    "    out_csv = Path(out_csv)\n",
    "    flat = preds.transpose(1, 2, 0).reshape(-1, preds.shape[0])\n",
    "    columns = [f\"{idx}.png\" for idx in range(preds.shape[0])]\n",
    "    index = [f\"Pixel {idx}\" for idx in range(flat.shape[0])]\n",
    "\n",
    "    df = pd.DataFrame(flat, index=index, columns=columns)\n",
    "    df.index.name = \"\"\n",
    "    df.to_csv(out_csv)\n",
    "    print(f\"Saved CSV predictions to {out_csv} with shape {df.shape}\")\n",
    "\n",
    "    if save_npy:\n",
    "        np.save(out_csv.with_suffix(\".npy\"), preds.astype(np.uint8))\n",
    "        print(f\"Saved NumPy predictions to {out_csv.with_suffix('.npy')}\")\n",
    "\n",
    "\n",
    "def load_ground_truth(path: str | Path, *, expected_hw: Tuple[int, int]) -> np.ndarray:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    numeric_df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    numeric_df = numeric_df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "    if numeric_df.isnull().values.any():\n",
    "        raise ValueError(\n",
    "            \"Ground-truth CSV contains non-numeric values even after coercion. \"\n",
    "            \"Please ensure labels are stored as integers.\"\n",
    "        )\n",
    "\n",
    "    flat = numeric_df.to_numpy(dtype=np.int16, copy=False).T\n",
    "    h, w = expected_hw\n",
    "    return flat.reshape(flat.shape[0], h, w)\n",
    "\n",
    "\n",
    "def evaluate_ari(preds: np.ndarray, y_true: np.ndarray) -> Dict[str, float]:\n",
    "    if preds.shape != y_true.shape:\n",
    "        n_min = min(preds.shape[0], y_true.shape[0])\n",
    "        preds = preds[:n_min]\n",
    "        y_true = y_true[:n_min]\n",
    "        print(f\"Aligned prediction and ground-truth stacks to {n_min} slices\")\n",
    "\n",
    "    scores: List[float] = []\n",
    "    for pred, gt in zip(preds, y_true):\n",
    "        mask = (pred > 0) & (gt > 0)\n",
    "        if mask.sum() < 20:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "        scores.append(adjusted_rand_score(gt[mask].ravel(), pred[mask].ravel()))\n",
    "\n",
    "    stats = {\n",
    "        \"mean\": float(np.mean(scores)) if scores else 0.0,\n",
    "        \"median\": float(np.median(scores)) if scores else 0.0,\n",
    "        \"min\": float(np.min(scores)) if scores else 0.0,\n",
    "        \"max\": float(np.max(scores)) if scores else 0.0,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        \"ARI statistics -> \"\n",
    "        f\"mean: {stats['mean']:.4f}, median: {stats['median']:.4f}, \"\n",
    "        f\"min: {stats['min']:.4f}, max: {stats['max']:.4f}\"\n",
    "    )\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7a866",
   "metadata": {},
   "source": [
    "## Foreground-Boosted Pipeline (RandomForest + K-means)\n",
    "Cette section ajoute la couche « supervisée » : une Random Forest apprend à distinguer le fond des structures à partir d’un échantillon de slices annotées. On utilise ensuite ce masque de confiance pour ne segmenter via K-means que les pixels vraiment intéressants. Les fonctions définies ici (configurations, entraînement RF, segmentation et visualisation) permettent de lancer un pipeline complet sur un jeu d’apprentissage, d’évaluer la qualité avec l’ARI du challenge et d’exporter des aperçus visuels.\n",
    "\n",
    "> **Choix de l’algorithme de clustering** : c’est la valeur passée via `seg_cfg` (par exemple `seg_config = ImprovedKMeansHybridConfig(method=\"kmeans\")`) qui est utilisée par `run_demo`. Le champ `method` du dataclass ne fournit qu’une valeur par défaut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b40559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Foreground-boosted segmentation pipeline (RandomForest + improved K-means).\"\"\"\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Sequence\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class ImprovedKMeansHybridConfig:\n",
    "    k_structures: int = 14\n",
    "    extra_background_clusters: int = 2\n",
    "    subsample: int = 250_000\n",
    "    random_state: int = 7\n",
    "    method: str = \"minibatch\" # si on ne modifie rien, la methode par defaut sera la moins couteuse donc minibatch\n",
    "    sigmas: Sequence[float] = (0.8, 1.6, 2.4)\n",
    "    bg_margin: int = 6\n",
    "    post_min_size: int = 80\n",
    "    post_hole_size: int = 96\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class ForegroundClassifierConfig:\n",
    "    n_training_slices: int = 40\n",
    "    pixels_per_class: int = 8_000\n",
    "    random_state: int = 7\n",
    "    n_estimators: int = 400\n",
    "    max_depth: int | None = 20\n",
    "    min_samples_leaf: int = 10\n",
    "    probability_threshold: float = 0.5\n",
    "\n",
    "\n",
    "def _sample_training_pixels(\n",
    "    stack: np.ndarray,\n",
    "    masks: np.ndarray,\n",
    "    seg_cfg: ImprovedKMeansHybridConfig,\n",
    "    clf_cfg: ForegroundClassifierConfig,\n",
    "    *,\n",
    "    chosen_indices: Sequence[int] | None = None,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = check_random_state(clf_cfg.random_state)\n",
    "    if chosen_indices is None:\n",
    "        n_slices = stack.shape[0]\n",
    "        choose = min(clf_cfg.n_training_slices, n_slices)\n",
    "        chosen_indices = rng.choice(n_slices, size=choose, replace=False)\n",
    "    else:\n",
    "        chosen_indices = np.array(chosen_indices, dtype=int)\n",
    "\n",
    "    features_list: List[np.ndarray] = []\n",
    "    labels_list: List[np.ndarray] = []\n",
    "\n",
    "    for idx in chosen_indices:\n",
    "        raw_slice = stack[idx]\n",
    "        gt_slice = masks[idx]\n",
    "\n",
    "        bundle = build_feature_bundle(raw_slice, sigmas=seg_cfg.sigmas)\n",
    "        flat_features = bundle.matrix\n",
    "        flat_labels = (gt_slice.ravel() > 0).astype(np.uint8)\n",
    "\n",
    "        for cls_val in (0, 1):\n",
    "            cls_idx = np.flatnonzero(flat_labels == cls_val)\n",
    "            if cls_idx.size == 0:\n",
    "                continue\n",
    "\n",
    "            sample_size = min(cls_idx.size, clf_cfg.pixels_per_class)\n",
    "            sampled_idx = rng.choice(cls_idx, size=sample_size, replace=False)\n",
    "\n",
    "            features_list.append(flat_features[sampled_idx])\n",
    "            labels_list.append(flat_labels[sampled_idx])\n",
    "\n",
    "    if not features_list:\n",
    "        raise RuntimeError(\"No training pixels were sampled. Check ground truth availability.\")\n",
    "\n",
    "    X_train = np.concatenate(features_list, axis=0)\n",
    "    y_train = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "    return X_train.astype(np.float32), y_train.astype(np.uint8)\n",
    "\n",
    "\n",
    "def train_foreground_classifier(\n",
    "    stack: np.ndarray,\n",
    "    masks: np.ndarray,\n",
    "    seg_cfg: ImprovedKMeansHybridConfig,\n",
    "    clf_cfg: ForegroundClassifierConfig,\n",
    "    *,\n",
    "    chosen_indices: Sequence[int] | None = None,\n",
    ") -> RandomForestClassifier:\n",
    "    start = time.time()\n",
    "    X_train, y_train = _sample_training_pixels(\n",
    "        stack,\n",
    "        masks,\n",
    "        seg_cfg,\n",
    "        clf_cfg,\n",
    "        chosen_indices=chosen_indices,\n",
    "    )\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=clf_cfg.n_estimators,\n",
    "        max_depth=clf_cfg.max_depth,\n",
    "        min_samples_leaf=clf_cfg.min_samples_leaf,\n",
    "        n_jobs=-1,\n",
    "        random_state=clf_cfg.random_state,\n",
    "        oob_score=False,\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print(\n",
    "        f\"Trained foreground classifier on {len(y_train):,} pixels \"\n",
    "        f\"(class balance: {y_train.sum():,} foreground / {(y_train==0).sum():,} background) \"\n",
    "        f\"in {elapsed:.1f}s\"\n",
    "    )\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class ForegroundBoostedImprovedKMeans:\n",
    "    seg_cfg: ImprovedKMeansHybridConfig = field(default_factory=ImprovedKMeansHybridConfig)\n",
    "    clf_cfg: ForegroundClassifierConfig = field(default_factory=ForegroundClassifierConfig)\n",
    "    classifier: RandomForestClassifier | None = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        stack: np.ndarray,\n",
    "        masks: np.ndarray,\n",
    "        *,\n",
    "        chosen_indices: Sequence[int] | None = None,\n",
    "    ) -> \"ForegroundBoostedImprovedKMeans\":\n",
    "        self.classifier = train_foreground_classifier(\n",
    "            stack,\n",
    "            masks,\n",
    "            self.seg_cfg,\n",
    "            self.clf_cfg,\n",
    "            chosen_indices=chosen_indices,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def _segment_single(self, raw_slice: np.ndarray, slice_idx: int) -> np.ndarray:\n",
    "        if self.classifier is None:\n",
    "            raise RuntimeError(\"Classifier must be trained before inference.\")\n",
    "\n",
    "        cfg = self.seg_cfg\n",
    "        bundle = build_feature_bundle(raw_slice, sigmas=cfg.sigmas)\n",
    "        h, w = raw_slice.shape\n",
    "\n",
    "        proba = self.classifier.predict_proba(bundle.matrix)[:, 1]\n",
    "        structure_mask = proba.reshape(h, w) >= self.clf_cfg.probability_threshold\n",
    "\n",
    "        k_total = cfg.k_structures + cfg.extra_background_clusters\n",
    "        labels, _ = _fit_clusterer(\n",
    "            bundle.matrix,\n",
    "            k_total,\n",
    "            cfg.subsample,\n",
    "            cfg.random_state + slice_idx,\n",
    "            cfg.method,\n",
    "        )\n",
    "\n",
    "        label_img = labels.reshape(h, w)\n",
    "        background_label = _pick_background_label(labels, bundle.maps, margin=cfg.bg_margin)\n",
    "        label_img[label_img == background_label] = 0\n",
    "        label_img[~structure_mask] = 0\n",
    "\n",
    "        label_img, _, _ = relabel_sequential(label_img)\n",
    "        processed = _post_process(\n",
    "            label_img,\n",
    "            bundle.maps,\n",
    "            min_size=cfg.post_min_size,\n",
    "            hole_size=cfg.post_hole_size,\n",
    "        )\n",
    "        processed[~structure_mask] = 0\n",
    "\n",
    "        return processed.astype(np.uint8)\n",
    "\n",
    "    def segment_stack(self, stack: np.ndarray, verbose: bool = True) -> np.ndarray:\n",
    "        preds: List[np.ndarray] = []\n",
    "        start = time.time()\n",
    "\n",
    "        for idx, slc in enumerate(stack):\n",
    "            pred = self._segment_single(slc, slice_idx=idx)\n",
    "            preds.append(pred)\n",
    "\n",
    "            if verbose and (idx + 1) % 25 == 0:\n",
    "                elapsed = time.time() - start\n",
    "                rate = (idx + 1) / max(elapsed, 1e-6)\n",
    "                print(f\"Processed {idx + 1} slices in {elapsed:.1f}s ({rate:.2f} slices/s)\")\n",
    "\n",
    "        return np.stack(preds, axis=0)\n",
    "\n",
    "\n",
    "def evaluate_ari_challenge(preds: np.ndarray, y_true: np.ndarray) -> Dict[str, float]:\n",
    "    if preds.shape != y_true.shape:\n",
    "        n_min = min(preds.shape[0], y_true.shape[0])\n",
    "        preds = preds[:n_min]\n",
    "        y_true = y_true[:n_min]\n",
    "        print(f\"Aligned prediction and ground-truth stacks to {n_min} slices\")\n",
    "\n",
    "    scores: List[float] = []\n",
    "    for pred, gt in zip(preds, y_true):\n",
    "        scores.append(adjusted_rand_score(gt.ravel(), pred.ravel()))\n",
    "\n",
    "    stats = {\n",
    "        \"mean\": float(np.mean(scores)) if scores else 0.0,\n",
    "        \"median\": float(np.median(scores)) if scores else 0.0,\n",
    "        \"min\": float(np.min(scores)) if scores else 0.0,\n",
    "        \"max\": float(np.max(scores)) if scores else 0.0,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        \"ARI statistics (challenge metric) -> \"\n",
    "        f\"mean: {stats['mean']:.4f}, median: {stats['median']:.4f}, \"\n",
    "        f\"min: {stats['min']:.4f}, max: {stats['max']:.4f}\"\n",
    "    )\n",
    "    return stats\n",
    "\n",
    "\n",
    "def save_visual_report(\n",
    "    raw_stack: np.ndarray,\n",
    "    gt_stack: np.ndarray,\n",
    "    preds: np.ndarray,\n",
    "    eval_files: Sequence[Path],\n",
    "    *,\n",
    "    output_dir: str | Path,\n",
    "    max_examples: int = 6,\n",
    ") -> List[Path]:\n",
    "    if preds.size == 0:\n",
    "        raise ValueError(\"No predictions available for visualization.\")\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError as exc:\n",
    "        raise RuntimeError(\"matplotlib is required for visualization\") from exc\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    max_examples = max(1, min(int(max_examples), preds.shape[0]))\n",
    "    per_slice_scores: List[Tuple[int, float]] = []\n",
    "    for idx, (pred, gt) in enumerate(zip(preds, gt_stack)):\n",
    "        score = adjusted_rand_score(gt.ravel(), pred.ravel())\n",
    "        per_slice_scores.append((idx, score))\n",
    "\n",
    "    per_slice_scores.sort(key=lambda item: item[1])\n",
    "    score_lookup = {idx: score for idx, score in per_slice_scores}\n",
    "    bottom = max(1, max_examples // 2)\n",
    "    top = max_examples - bottom\n",
    "\n",
    "    selected: List[int] = [idx for idx, _ in per_slice_scores[:bottom]]\n",
    "    if top > 0:\n",
    "        selected.extend(idx for idx, _ in per_slice_scores[-top:])\n",
    "\n",
    "    ordered_unique: List[int] = []\n",
    "    seen = set()\n",
    "    for idx in selected:\n",
    "        if idx not in seen:\n",
    "            seen.add(idx)\n",
    "            ordered_unique.append(idx)\n",
    "\n",
    "    n_rows = len(ordered_unique)\n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(9, 3 * n_rows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    cmap_mask = \"nipy_spectral\"\n",
    "    saved_paths: List[Path] = []\n",
    "    for row, local_idx in enumerate(ordered_unique):\n",
    "        raw = raw_stack[local_idx]\n",
    "        gt = gt_stack[local_idx]\n",
    "        pred = preds[local_idx]\n",
    "        slice_name = Path(eval_files[local_idx]).name if eval_files else f\"slice_{local_idx}\"\n",
    "        score = score_lookup.get(local_idx, float(\"nan\"))\n",
    "\n",
    "        axes[row, 0].imshow(raw, cmap=\"gray\")\n",
    "        axes[row, 0].set_title(f\"{slice_name}\\nRaw\")\n",
    "        axes[row, 1].imshow(gt, cmap=cmap_mask, interpolation=\"nearest\")\n",
    "        axes[row, 1].set_title(\"Vérité terrain\")\n",
    "        axes[row, 2].imshow(pred, cmap=cmap_mask, interpolation=\"nearest\")\n",
    "        axes[row, 2].set_title(f\"Prédiction\\nARI={score:.3f}\")\n",
    "\n",
    "        for col in range(3):\n",
    "            axes[row, col].axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    preview_path = output_dir / \"foreground_boosted_improved_preview.png\"\n",
    "    fig.savefig(preview_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    saved_paths.append(preview_path)\n",
    "    return saved_paths\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Convenience runner\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_demo(\n",
    "    train_img_dir: str | Path,\n",
    "    y_train_path: str | Path,\n",
    "    *,\n",
    "    seg_cfg: ImprovedKMeansHybridConfig | None = None,\n",
    "    clf_cfg: ForegroundClassifierConfig | None = None,\n",
    "    n_slices: int | None = 200,\n",
    "    output_csv: str | Path = \"predictions_foreground_boosted_improved.csv\",\n",
    "    preview_dir: str | Path | None = None,\n",
    "    preview_max_examples: int = 6,\n",
    ") -> Dict[str, float]:\n",
    "    seg_cfg = seg_cfg or ImprovedKMeansHybridConfig()\n",
    "    clf_cfg = clf_cfg or ForegroundClassifierConfig()\n",
    "\n",
    "    files, stack = load_png_stack(train_img_dir, limit=n_slices)\n",
    "    print(f\"Loaded {len(files)} slices of shape {stack.shape[1:]} from {train_img_dir}\")\n",
    "\n",
    "    y_true = load_ground_truth(y_train_path, expected_hw=stack.shape[1:])\n",
    "    if y_true.shape[0] < stack.shape[0]:\n",
    "        print(\n",
    "            f\"Warning: ground truth has only {y_true.shape[0]} slices; aligning annotations to data.\"\n",
    "        )\n",
    "    y_true = y_true[: stack.shape[0]]\n",
    "\n",
    "    rng = np.random.RandomState(clf_cfg.random_state)\n",
    "    total_slices = stack.shape[0]\n",
    "    train_size = min(clf_cfg.n_training_slices, total_slices)\n",
    "    if train_size >= total_slices:\n",
    "        train_size = max(total_slices - 1, 1)\n",
    "        print(\n",
    "            \"Adjusted training slice count to leave at least one slice for evaluation.\"\n",
    "        )\n",
    "\n",
    "    train_indices = rng.choice(total_slices, size=train_size, replace=False)\n",
    "    eval_mask = np.ones(total_slices, dtype=bool)\n",
    "    eval_mask[train_indices] = False\n",
    "    eval_indices = np.flatnonzero(eval_mask)\n",
    "\n",
    "    if eval_indices.size == 0:\n",
    "        raise RuntimeError(\n",
    "            \"Evaluation set is empty. Reduce `n_training_slices` to leave holdout slices.\"\n",
    "        )\n",
    "\n",
    "    train_stack = stack[train_indices]\n",
    "    train_masks = y_true[train_indices]\n",
    "    eval_stack = stack[eval_indices]\n",
    "    eval_masks = y_true[eval_indices]\n",
    "    eval_files = [files[idx] for idx in eval_indices]\n",
    "\n",
    "    print(\n",
    "        f\"Training RF on slices {train_indices.tolist()} (count={train_indices.size}), \"\n",
    "        f\"evaluating on slices {eval_indices.tolist()} (count={eval_indices.size}).\"\n",
    "    )\n",
    "\n",
    "    segmenter = ForegroundBoostedImprovedKMeans(seg_cfg=seg_cfg, clf_cfg=clf_cfg)\n",
    "    segmenter.fit(train_stack, train_masks, chosen_indices=range(train_stack.shape[0]))\n",
    "\n",
    "    preds = segmenter.segment_stack(eval_stack)\n",
    "\n",
    "    save_predictions(preds, output_csv)\n",
    "    stats = evaluate_ari_challenge(preds, eval_masks[: preds.shape[0]])\n",
    "\n",
    "    if preview_dir is not None:\n",
    "        preview_paths = save_visual_report(\n",
    "            eval_stack[: preds.shape[0]],\n",
    "            eval_masks[: preds.shape[0]],\n",
    "            preds,\n",
    "            eval_files[: preds.shape[0]],\n",
    "            output_dir=preview_dir,\n",
    "            max_examples=preview_max_examples,\n",
    "        )\n",
    "        if preview_paths:\n",
    "            joined = \", \".join(str(p) for p in preview_paths)\n",
    "            print(f\"Saved visual preview(s) to: {joined}\")\n",
    "            stats[\"preview_paths\"] = [str(p) for p in preview_paths]\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97f6cb",
   "metadata": {},
   "source": [
    "## Utilisation\n",
    "\n",
    "1. Installez les dépendances nécessaires :\n",
    "   ```bash\n",
    "   pip install numpy pandas pillow scikit-learn scikit-image matplotlib\n",
    "   ```\n",
    "2. Définissez les chemins d'accès aux dossiers d'images et au CSV des masques.\n",
    "3. Exécutez la cellule ci-dessous pour lancer un run d'entraînement/évaluation ou\n",
    "   adaptez-la pour générer des prédictions sur un autre jeu d'images (ex : `X_test`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3cca5",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessus, on peut modifier les parametres du Kmean (ou du minibatch) pour essayer d'optimiser les résultats\n",
    "Par exemple on modifiant, le nombre de structures à identifier, ou le nombre de pixel à prendre en compte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9faa6bd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No PNG image found in /path/vers/X_train/images",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     17\u001b[39m clf_config = ForegroundClassifierConfig(\n\u001b[32m     18\u001b[39m     n_training_slices=\u001b[32m40\u001b[39m,\n\u001b[32m     19\u001b[39m     pixels_per_class=\u001b[32m8_000\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     probability_threshold=\u001b[32m0.5\u001b[39m,\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Lancement d'un run démo : entraînement RF sur un sous-ensemble, évaluation hold-out.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m stats = \u001b[43mrun_demo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_img_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAIN_IMG_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mY_TRAIN_CSV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseg_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseg_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclf_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclf_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_slices\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpredictions_foreground_boosted_improved.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreview_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreports/foreground_boosted_improved\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreview_max_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m stats\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 312\u001b[39m, in \u001b[36mrun_demo\u001b[39m\u001b[34m(train_img_dir, y_train_path, seg_cfg, clf_cfg, n_slices, output_csv, preview_dir, preview_max_examples)\u001b[39m\n\u001b[32m    309\u001b[39m seg_cfg = seg_cfg \u001b[38;5;129;01mor\u001b[39;00m ImprovedKMeansHybridConfig()\n\u001b[32m    310\u001b[39m clf_cfg = clf_cfg \u001b[38;5;129;01mor\u001b[39;00m ForegroundClassifierConfig()\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m files, stack = \u001b[43mload_png_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_img_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_slices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m slices of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstack.shape[\u001b[32m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_img_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    315\u001b[39m y_true = load_ground_truth(y_train_path, expected_hw=stack.shape[\u001b[32m1\u001b[39m:])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mload_png_stack\u001b[39m\u001b[34m(img_dir, limit)\u001b[39m\n\u001b[32m      7\u001b[39m pngs = \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m      8\u001b[39m     img_dir.glob(\u001b[33m\"\u001b[39m\u001b[33m*.png\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      9\u001b[39m     key=\u001b[38;5;28;01mlambda\u001b[39;00m f: \u001b[38;5;28mint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(ch \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m f.stem \u001b[38;5;28;01mif\u001b[39;00m ch.isdigit()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m),\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pngs:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo PNG image found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m     pngs = pngs[:limit]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No PNG image found in /path/vers/X_train/images"
     ]
    }
   ],
   "source": [
    "# Exemple d'exécution (adapter les chemins à votre environnement)\n",
    "TRAIN_IMG_DIR = Path(\"/path/vers/X_train/images\")\n",
    "Y_TRAIN_CSV = Path(\"/path/vers/Y_train.csv\")\n",
    "\n",
    "seg_config = ImprovedKMeansHybridConfig(\n",
    "    k_structures=14, #initialement 12, on essai 10 ou 14\n",
    "    extra_background_clusters=2,\n",
    "    subsample=250_000, #initialement 150_000, on essai 200 000 si possible\n",
    "    random_state=7,\n",
    "    method=\"minibatch\",  # mettre \"kmeans\" si on veut K-mean (attention à l'orthographe)\n",
    "    sigmas=(0.8, 1.6, 2.4), #initialement 0.8, 1.6, 2.4, on essai peut essayer une echelle plus douce  0.6, 1.2, 2.4, 3.2)\n",
    "    bg_margin=6, \n",
    "    post_min_size=80, \n",
    "    post_hole_size=96, \n",
    ")\n",
    "\n",
    "clf_config = ForegroundClassifierConfig(\n",
    "    n_training_slices=40,\n",
    "    pixels_per_class=8_000,\n",
    "    random_state=7,\n",
    "    n_estimators=400,\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=10,\n",
    "    probability_threshold=0.5,\n",
    ")\n",
    "\n",
    "# Lancement d'un run démo : entraînement RF sur un sous-ensemble, évaluation hold-out.\n",
    "stats = run_demo(\n",
    "    train_img_dir=TRAIN_IMG_DIR,\n",
    "    y_train_path=Y_TRAIN_CSV,\n",
    "    seg_cfg=seg_config,\n",
    "    clf_cfg=clf_config,\n",
    "    n_slices=200,\n",
    "    output_csv=\"predictions_foreground_boosted_improved.csv\",\n",
    "    preview_dir=\"reports/foreground_boosted_improved\",\n",
    "    preview_max_examples=6,\n",
    ")\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f20c3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
